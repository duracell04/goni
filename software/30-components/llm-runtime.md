# LLM Runtime\n\nRuntime assumptions for local model serving.
